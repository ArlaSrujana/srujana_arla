{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5fc1ad9-9591-46f4-bfb7-46b868d517f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing LocalOutlierFactor...\n",
      "\n",
      "Model: LocalOutlierFactor\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.00      0.00      0.00      1754\n",
      "           1       0.57      0.88      0.69      2520\n",
      "\n",
      "    accuracy                           0.52      4274\n",
      "   macro avg       0.19      0.29      0.23      4274\n",
      "weighted avg       0.34      0.52      0.41      4274\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   0    0    0]\n",
      " [  92    0 1662]\n",
      " [ 304    0 2216]]\n",
      "Analyzing OneClassSVM...\n",
      "\n",
      "Model: OneClassSVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.29      0.25      1754\n",
      "           1       0.40      0.33      0.36      2520\n",
      "\n",
      "    accuracy                           0.31      4274\n",
      "   macro avg       0.31      0.31      0.31      4274\n",
      "weighted avg       0.33      0.31      0.31      4274\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 502 1252]\n",
      " [1700  820]]\n",
      "Analyzing KNeighborsClassifier...\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      1754\n",
      "           1       0.93      0.92      0.93      2520\n",
      "\n",
      "    accuracy                           0.92      4274\n",
      "   macro avg       0.91      0.91      0.91      4274\n",
      "weighted avg       0.92      0.92      0.92      4274\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1588  166]\n",
      " [ 196 2324]]\n",
      "Analyzing RandomForestClassifier...\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1754\n",
      "           1       0.99      0.99      0.99      2520\n",
      "\n",
      "    accuracy                           0.99      4274\n",
      "   macro avg       0.99      0.99      0.99      4274\n",
      "weighted avg       0.99      0.99      0.99      4274\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1723   31]\n",
      " [  27 2493]]\n",
      "Analyzing GradientBoostingClassifier...\n",
      "\n",
      "Model: GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1754\n",
      "           1       0.99      0.99      0.99      2520\n",
      "\n",
      "    accuracy                           0.99      4274\n",
      "   macro avg       0.99      0.99      0.99      4274\n",
      "weighted avg       0.99      0.99      0.99      4274\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1735   19]\n",
      " [  18 2502]]\n",
      "Analyzing DecisionTreeClassifier...\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1754\n",
      "           1       0.99      0.99      0.99      2520\n",
      "\n",
      "    accuracy                           0.99      4274\n",
      "   macro avg       0.99      0.99      0.99      4274\n",
      "weighted avg       0.99      0.99      0.99      4274\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1732   22]\n",
      " [  19 2501]]\n",
      "\n",
      "Summary of Results:\n",
      "                        Model  Precision    Recall  F1-Score  False Positives  \\\n",
      "0          LocalOutlierFactor   0.571429  0.879365  0.692716                0   \n",
      "1                 OneClassSVM   0.395753  0.325397  0.357143             1252   \n",
      "2        KNeighborsClassifier   0.933333  0.922222  0.927745              166   \n",
      "3      RandomForestClassifier   0.987718  0.989286  0.988501               31   \n",
      "4  GradientBoostingClassifier   0.992463  0.992857  0.992660               19   \n",
      "5      DecisionTreeClassifier   0.991280  0.992460  0.991870               22   \n",
      "\n",
      "   False Negatives  \n",
      "0               92  \n",
      "1             1700  \n",
      "2              196  \n",
      "3               27  \n",
      "4               18  \n",
      "5               19  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor, KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"dataset.csv\"  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing: Ensure numeric data\n",
    "# Convert datetime columns to numeric (Unix timestamp)\n",
    "for col in data.select_dtypes(include=['object', 'datetime']):\n",
    "    try:\n",
    "        data[col] = pd.to_datetime(data[col], errors='coerce').astype(int) / 10**9\n",
    "    except:\n",
    "        pass  # Skip non-datetime columns\n",
    "\n",
    "# Drop or encode remaining non-numeric columns\n",
    "data = pd.get_dummies(data, drop_first=True)  # One-hot encoding for categorical data\n",
    "\n",
    "# Ensure no missing values\n",
    "data = data.dropna()  # Drop rows with missing values or handle them appropriately\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop(columns=['label'])  # Replace 'label' with your actual label column name\n",
    "y = data['label']  # Binary labels: 1 for normal, 0 for anomaly\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the data to avoid large values affecting models (especially OneClassSVM)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"LocalOutlierFactor\": LocalOutlierFactor(n_neighbors=20, novelty=True, contamination=0.1),\n",
    "    \"OneClassSVM\": OneClassSVM(kernel=\"rbf\", gamma=0.1),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=42),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "def analyze_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    if hasattr(model, 'fit_predict'):  # For LOF\n",
    "        model.fit(X_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = np.where(y_pred == 1, 1, 0)  # Convert LOF output to binary\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Precision\": report['1']['precision'],\n",
    "        \"Recall\": report['1']['recall'],\n",
    "        \"F1-Score\": report['1']['f1-score'],\n",
    "        \"False Positives\": cm[0][1],\n",
    "        \"False Negatives\": cm[1][0]\n",
    "    }\n",
    "\n",
    "# Perform analysis\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Analyzing {model_name}...\")\n",
    "    result = analyze_model(model, X_train_scaled, X_test_scaled, y_train, y_test, model_name)\n",
    "    results.append(result)\n",
    "\n",
    "# Convert results to DataFrame for summary\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save results to CSV (optional)\n",
    "results_df.to_csv(\"model_discrepancy_analysis.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8862d-53a3-48b6-a9c2-fc1ed0cfd19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
